<!DOCTYPE html>
<html lang="es">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Quiz ML - Master Edition con Feedback</title>
    <style>
        :root {
            --primary-color: #2563eb;
            --success-color: #22c55e;
            --error-color: #ef4444;
            --bg-color: #f3f4f6;
            --card-bg: #ffffff;
            --text-color: #1f2937;
            --border-color: #e5e7eb;
        }

        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            background-color: var(--bg-color);
            color: var(--text-color);
            display: flex;
            justify-content: center;
            align-items: center;
            min-height: 100vh;
            margin: 0;
            padding: 20px;
            box-sizing: border-box;
        }

        .quiz-container {
            background-color: var(--card-bg);
            border-radius: 12px;
            box-shadow: 0 10px 25px -5px rgba(0, 0, 0, 0.1);
            width: 100%;
            max-width: 650px;
            overflow: hidden;
            display: flex;
            flex-direction: column;
            max-height: 90vh;
        }

        .header {
            background-color: var(--primary-color);
            color: white;
            padding: 15px;
            text-align: center;
            flex-shrink: 0;
        }

        .header h1 { margin: 0; font-size: 1.2rem; }

        .progress-bar {
            height: 6px;
            background-color: rgba(255, 255, 255, 0.3);
            margin-top: 10px;
            border-radius: 3px;
            overflow: hidden;
        }

        .progress-fill {
            height: 100%;
            background-color: #ffffff;
            width: 0%;
            transition: width 0.3s ease;
        }

        .quiz-body {
            padding: 25px;
            overflow-y: auto;
        }

        .question-text {
            font-size: 1.1rem;
            font-weight: 600;
            margin-bottom: 20px;
            line-height: 1.5;
        }

        .options-list {
            display: flex;
            flex-direction: column;
            gap: 10px;
        }

        .option-btn {
            background-color: white;
            border: 2px solid var(--border-color);
            border-radius: 8px;
            padding: 12px 15px;
            text-align: left;
            cursor: pointer;
            font-size: 0.95rem;
            transition: all 0.2s;
            color: var(--text-color);
        }

        .option-btn:hover:not(:disabled) {
            border-color: var(--primary-color);
            background-color: #eff6ff;
        }
        .option-btn:disabled { cursor: default; }
        .option-btn.correct {
            background-color: #dcfce7;
            border-color: var(--success-color);
            color: #14532d;
        }
        .option-btn.incorrect {
            background-color: #fee2e2;
            border-color: var(--error-color);
            color: #7f1d1d;
        }

        .feedback {
            margin-top: 20px;
            display: none;
            animation: fadeIn 0.3s;
        }

        .explanation-box {
            background-color: #f8fafc;
            border-left: 4px solid var(--primary-color);
            padding: 10px 15px;
            margin-top: 10px;
            font-size: 0.9rem;
            color: #4b5563;
            line-height: 1.4;
        }

        @keyframes fadeIn {
            from { opacity: 0; transform: translateY(5px); }
            to { opacity: 1; transform: translateY(0); }
        }

        .controls {
            padding: 15px 25px;
            border-top: 1px solid var(--border-color);
            display: flex;
            justify-content: flex-end;
            align-items: center;
            background-color: #fff;
            flex-shrink: 0;
        }

        .btn {
            background-color: var(--primary-color);
            color: white;
            border: none;
            padding: 10px 20px;
            border-radius: 6px;
            cursor: pointer;
            font-size: 1rem;
            font-weight: 500;
            transition: background-color 0.2s;
        }
        .btn:hover { background-color: #1d4ed8; }
        .btn:disabled { background-color: #9ca3af; cursor: not-allowed; }

        .result-screen {
            text-align: center;
            padding: 20px 30px;
            display: none;
            overflow-y: auto;
            max-height: 100%;
        }

        .grade-circle {
            width: 120px;
            height: 120px;
            background-color: var(--primary-color);
            color: white;
            border-radius: 50%;
            display: flex;
            flex-direction: column;
            justify-content: center;
            align-items: center;
            margin: 0 auto 15px auto;
            box-shadow: 0 4px 6px rgba(0,0,0,0.1);
        }
        
        .final-grade { font-size: 2.8rem; font-weight: bold; line-height: 1; }
        .grade-label { font-size: 0.8rem; opacity: 0.9; margin-top: 5px; }

        .raw-score-small {
            font-size: 0.9rem;
            color: #6b7280;
            margin-bottom: 20px;
            font-weight: 500;
        }

        .recommendation-box {
            background-color: #fffbeb;
            border: 1px solid #fcd34d;
            border-radius: 8px;
            padding: 15px;
            margin: 20px 0;
            text-align: left;
        }

        .recommendation-title { font-weight: bold; color: #92400e; margin-bottom: 8px; display: block; }
        .recommendation-text { font-size: 0.95rem; color: #78350f; line-height: 1.4; }

        .review-container {
            text-align: left;
            margin-top: 20px;
            border-top: 1px solid var(--border-color);
            padding-top: 20px;
        }

        .review-item {
            background-color: #f9fafb;
            border: 1px solid var(--border-color);
            border-radius: 8px;
            padding: 12px;
            margin-bottom: 10px;
            border-left: 4px solid transparent;
            font-size: 0.9rem;
        }

        .review-item.correct-item { border-left-color: var(--success-color); }
        .review-item.wrong-item { border-left-color: var(--error-color); }
        .review-q { font-weight: bold; margin-bottom: 6px; }
        
        .tag-pill {
            display: inline-block;
            font-size: 0.7rem;
            background-color: #e5e7eb;
            padding: 2px 6px;
            border-radius: 4px;
            margin-left: 5px;
            color: #4b5563;
        }

    </style>
</head>
<body>

<div class="quiz-container">
    <div class="header">
        <h1>Evaluaci칩n Machine Learning</h1>
        <div class="progress-bar">
            <div class="progress-fill" id="progress"></div>
        </div>
    </div>

    <div class="quiz-body" id="question-screen">
        <div class="question-text" id="question">Cargando...</div>
        <div class="options-list" id="options"></div>
        <div class="feedback" id="feedback"></div>
    </div>

    <div class="result-screen" id="result-screen">
        <h2>Resultados Finales</h2>
        <div class="grade-circle">
            <div class="final-grade" id="final-grade">0.0</div>
            <div class="grade-label">NOTA FINAL</div>
        </div>
        <div class="raw-score-small">Aciertos totales: <span id="final-raw-score">0 / 0</span></div>
        <div class="recommendation-box" id="rec-box" style="display:none;">
            <span class="recommendation-title">游눠 Recomendaci칩n de Estudio:</span>
            <div class="recommendation-text" id="rec-text"></div>
        </div>
        <button class="btn" onclick="initQuiz()">Volver a intentar</button>
        <div class="review-container" id="review-list"></div>
    </div>

    <div class="controls" id="controls">
        <button class="btn" id="next-btn" onclick="nextQuestion()" disabled>Siguiente</button>
    </div>
</div>

<script>
    // --- BASE DE DATOS MASIVA (72 Preguntas con Explicaciones) ---
    const rawData = [
        // === BLOQUE 1: FUNDAMENTOS ===
        {
            topic: "Procesos de ML",
            question: "쮺u치l NO es una etapa dentro del proceso general de modelado del aprendizaje autom치tico?",
            explanation: "Las etapas clave son Definir el problema, Dividir datos y Entrenar. 'Numerar los ejemplos' es irrelevante para el aprendizaje del modelo.",
            options: [
                { text: "Definir el problema", isCorrect: false },
                { text: "Dividir el conjunto de entrenamiento y test", isCorrect: false },
                { text: "Entrenar el modelo", isCorrect: false },
                { text: "Numerar los ejemplos de entrenamiento", isCorrect: true }
            ]
        },
        {
            topic: "Validaci칩n de Modelos",
            question: "La validaci칩n cruzada consiste en:",
            explanation: "Cross-validation implica rotar qu칠 parte de los datos se usa para validar. Se divide en K grupos y se iteran K veces.",
            options: [
                { text: "Generar 5 conjuntos de entrenamiento para entrenar el modelo", isCorrect: false },
                { text: "Dividir en k grupos los datos y usar uno como test en cada iteraci칩n", isCorrect: true },
                { text: "Utilizar la t칠cnica de hold-out una sola vez", isCorrect: false },
                { text: "Dividir los datos en k grupos y entrenar un modelo diferente con cada grupo", isCorrect: false }
            ]
        },
        {
            topic: "Validaci칩n de Modelos",
            question: "En el ejercicio del iris realizado en Python, la alta exactitud es debido a:",
            explanation: "El dataset Iris es famoso por ser simple, peque침o y tener clases muy separables, lo que facilita que cualquier modelo logre alta exactitud.",
            options: [
                { text: "Es producto del azar", isCorrect: false },
                { text: "Es un dataset muy sencillo que alcanza buena exactitud con cualquier modelo", isCorrect: true },
                { text: "Tiene la cantidad de datos 칩ptima para entrenar", isCorrect: false },
                { text: "Tiene el mismo n칰mero de datos por cada clase", isCorrect: false }
            ]
        },
        // === BLOQUE 2: TERMINOLOG칈A ===
        {
            topic: "Terminolog칤a B치sica",
            question: "쮺u치l NO es un nombre con el que se le conoce a la variable respuesta?",
            explanation: "La variable respuesta se llama Clase, Objetivo (Target) o Label. 'Regressors' suele referirse a las variables predictoras.",
            options: [
                { text: "Clase", isCorrect: false },
                { text: "Variable objetivo", isCorrect: false },
                { text: "Target", isCorrect: false },
                { text: "Regressors", isCorrect: true }
            ]
        },
        {
            topic: "Terminolog칤a B치sica",
            question: "쮺u치l NO es un nombre para la variable predictora?",
            explanation: "La variable predictora es el Input, Feature o Variable Independiente. 'Clase' es lo que queremos predecir (output).",
            options: [
                { text: "Entrada o input", isCorrect: false },
                { text: "Class o clase", isCorrect: true },
                { text: "Variable independiente", isCorrect: false },
                { text: "Caracter칤sticas o features", isCorrect: false }
            ]
        },
        {
            topic: "Teor칤a de Funciones",
            question: "A la funci칩n f(x) ideal se la conoce con el nombre de:",
            explanation: "En estad칤stica y ML, la funci칩n ideal que mapea perfectamente X a Y se denomina funci칩n de regresi칩n verdadera.",
            options: [
                { text: "Funci칩n estimadora", isCorrect: false },
                { text: "Funci칩n perfecta", isCorrect: false },
                { text: "Funci칩n de regresi칩n", isCorrect: true },
                { text: "Funci칩n objetivo", isCorrect: false }
            ]
        },
        // === BLOQUE 3: TIPOS DE APRENDIZAJE ===
        {
            topic: "Tipos de Aprendizaje",
            question: "Verdadero o Falso: El aprendizaje supervisado se divide en problemas de agrupamiento y detecci칩n de anomal칤as.",
            explanation: "Falso. El supervisado se divide en Regresi칩n (n칰meros) y Clasificaci칩n (categor칤as). Agrupamiento es No Supervisado.",
            options: [
                { text: "Verdadero", isCorrect: false },
                { text: "Falso", isCorrect: true }
            ]
        },
        {
            topic: "Tipos de Aprendizaje",
            question: "Verdadero o Falso: El problema de agrupamiento consiste en dividir los datos en grupos con caracter칤sticas similares.",
            explanation: "Verdadero. El Clustering busca agrupar instancias que se parecen entre s칤 sin conocer sus etiquetas.",
            options: [
                { text: "Verdadero", isCorrect: true },
                { text: "Falso", isCorrect: false }
            ]
        },
        {
            topic: "Tipos de Aprendizaje",
            question: "Verdadero o Falso: El problema de detecci칩n de anomal칤as consiste en reducir la dimensionalidad para crear una nueva representaci칩n.",
            explanation: "Falso. Detecci칩n de anomal칤as busca datos at칤picos (outliers). Reducir dimensionalidad es PCA, t-SNE, etc.",
            options: [
                { text: "Verdadero", isCorrect: false },
                { text: "Falso", isCorrect: true }
            ]
        },
        {
            topic: "Tipos de Aprendizaje",
            question: "쯈u칠 tipos de aprendizajes principales existen dentro del machine learning?",
            explanation: "Los tres pilares son: Supervisado (con etiquetas), No Supervisado (sin etiquetas) y Refuerzo (premios/castigos).",
            options: [
                { text: "Supervisado, Autom치tico y General", isCorrect: false },
                { text: "Aprendizaje supervisado, no supervisado y por refuerzo", isCorrect: true },
                { text: "Solo supervisado y no supervisado", isCorrect: false },
                { text: "Solo autom치tico y por refuerzo", isCorrect: false }
            ]
        },
        {
            topic: "Tipos de Aprendizaje",
            question: "En el aprendizaje supervisado encontramos los siguientes tipos de problemas:",
            explanation: "Si predices una categor칤a es Clasificaci칩n; si predices un valor continuo num칠rico es Regresi칩n.",
            options: [
                { text: "Problemas de regresi칩n y clasificaci칩n", isCorrect: true },
                { text: "Problemas de no linealidad y generalizaci칩n", isCorrect: false },
                { text: "Solo problemas de regresi칩n", isCorrect: false },
                { text: "Solo problemas de clasificaci칩n", isCorrect: false }
            ]
        },
        {
            topic: "Teor칤a General",
            question: "Se침ale la afirmaci칩n FALSA sobre el aprendizaje autom치tico:",
            explanation: "No existe un 'algoritmo maestro'. El teorema 'No Free Lunch' dice que ning칰n algoritmo es el mejor para todos los problemas.",
            options: [
                { text: "El aprendizaje autom치tico es una rama de la IA", isCorrect: false },
                { text: "El aprendizaje autom치tico es una de las 치reas del Machine Learning", isCorrect: false },
                { text: "Existe un solo algoritmo de aprendizaje autom치tico que se adapta a cualquier circunstancia", isCorrect: true },
                { text: "Aprendizaje autom치tico y machine learning hacen referencia a lo mismo", isCorrect: false }
            ]
        },
        // === BLOQUE 4: REGRESI칍N & CLASIFICACI칍N ===
        {
            topic: "Regresi칩n",
            question: "Verdadero o Falso: El error cuadr치tico medio puede llegar a ser muy grande.",
            explanation: "Verdadero. Al no estar acotado (como el R2 que va de 0 a 1), el MSE puede ser enorme dependiendo de la escala de los datos.",
            options: [
                { text: "Verdadero", isCorrect: true },
                { text: "Falso", isCorrect: false }
            ]
        },
        {
            topic: "Regresi칩n",
            question: "Verdadero o Falso: Al entrenar un modelo de regresi칩n se dividen los datos en entrenamiento y test.",
            explanation: "Verdadero. Siempre se debe separar data para validar que el modelo generaliza y no solo memoriza.",
            options: [
                { text: "Verdadero", isCorrect: true },
                { text: "Falso", isCorrect: false }
            ]
        },
        {
            topic: "Regresi칩n",
            question: "Verdadero o Falso: El coeficiente de determinaci칩n puede ser un n칰mero muy grande (mayor a 1).",
            explanation: "Falso. El R-cuadrado (R2) tiene un valor m치ximo de 1 (predicci칩n perfecta). Si es negativo, el modelo es p칠simo.",
            options: [
                { text: "Verdadero", isCorrect: false },
                { text: "Falso", isCorrect: true }
            ]
        },
        {
            topic: "Clasificaci칩n",
            question: "La clasificaci칩n puede ser de tipo:",
            explanation: "Binaria (S칤/No, 0/1) o Multiclase (Perro/Gato/P치jaro).",
            options: [
                { text: "Lineal y Polin칩mica", isCorrect: false },
                { text: "Binaria y Multiclase", isCorrect: true },
                { text: "Regresiva y Lineal", isCorrect: false },
                { text: "Supervisada y No supervisada", isCorrect: false }
            ]
        },
        {
            topic: "Clasificaci칩n",
            question: "Si la probabilidad de pertenencia es 0.55 para la clase 1 y 0.45 para la clase 2, se puede afirmar que:",
            explanation: "El modelo predice la Clase 1 porque 0.55 > 0.45, pero la confianza es baja (est치 muy cerca del l칤mite de decisi칩n 0.50).",
            options: [
                { text: "Pertenece a la clase 2", isCorrect: false },
                { text: "No deber칤a clasificarse la instancia", isCorrect: false },
                { text: "Pertenece a la clase 1 y el l칤mite de pertenencia est치 muy cercano", isCorrect: true },
                { text: "El modelo ha fallado", isCorrect: false }
            ]
        },
        {
            topic: "Clasificaci칩n",
            question: "쯈u칠 vectores se deben tener preparados antes de crear la matriz de confusi칩n?",
            explanation: "Para comparar, necesitas el vector de las etiquetas reales (Ground Truth) y el vector de lo que predijo tu modelo.",
            options: [
                { text: "La tabla con verdaderos positivos y negativos", isCorrect: false },
                { text: "El vector de clasificaci칩n real y el vector de clasificaci칩n predicha", isCorrect: true },
                { text: "La variable a predecir", isCorrect: false },
                { text: "Solo los datos de test", isCorrect: false }
            ]
        },
        // === BLOQUE 5: ROC Y NA칊VE BAYES ===
        {
            topic: "Curvas ROC",
            question: "Verdadero o Falso: Una curva ROC es la representaci칩n gr치fica de la tasa de verdaderos positivos contra la tasa de falsos positivos.",
            explanation: "Verdadero. Muestra el compromiso entre sensibilidad (TPR) y 1-especificidad (FPR).",
            options: [
                { text: "Verdadero", isCorrect: true },
                { text: "Falso", isCorrect: false }
            ]
        },
        {
            topic: "Curvas ROC",
            question: "Verdadero o Falso: El objetivo directo de una curva ROC es clasificar bien las instancias.",
            explanation: "Falso. Su objetivo es evaluar la capacidad de diagn칩stico del modelo y ayudar a elegir el mejor umbral (threshold).",
            options: [
                { text: "Verdadero", isCorrect: false },
                { text: "Falso", isCorrect: true }
            ]
        },
        {
            topic: "Curvas ROC",
            question: "Verdadero o Falso: El 치rea bajo la curva (AUC) superior a 0,7 es un indicador de un buen modelo.",
            explanation: "Verdadero. 0.5 es azar. 1.0 es perfecto. Arriba de 0.7 empieza a considerarse aceptable/bueno.",
            options: [
                { text: "Verdadero", isCorrect: true },
                { text: "Falso", isCorrect: false }
            ]
        },
        {
            topic: "Na칦ve Bayes",
            question: "En la f칩rmula de Bayes, el t칠rmino P(Xi | Z) hace referencia a:",
            explanation: "Es la probabilidad a posteriori (o verosimilitud dependiendo de la notaci칩n estricta, pero en este contexto se refiere a la probabilidad condicionada inversa).",
            options: [
                { text: "Probabilidad a posteriori", isCorrect: true },
                { text: "Probabilidad de Z en la hip칩tesis Xi", isCorrect: false },
                { text: "Probabilidad a priori", isCorrect: false },
                { text: "Probabilidad condicionada", isCorrect: false }
            ]
        },
        {
            topic: "Na칦ve Bayes",
            question: "Si decimos que la probabilidad de que un mensaje sea spam es de 0.2 estamos hablando de:",
            explanation: "Es la probabilidad A Priori, es decir, lo que sabemos antes de analizar el contenido del mensaje (el 20% de todo el correo es spam).",
            options: [
                { text: "Probabilidad a posteriori", isCorrect: false },
                { text: "Probabilidad a priori", isCorrect: true },
                { text: "Probabilidad condicionada", isCorrect: false },
                { text: "Probabilidad de spam dada una condici칩n", isCorrect: false }
            ]
        },
        {
            topic: "Na칦ve Bayes",
            question: "Si la probabilidad de que un mensaje sea spam es de 0.7 se podr칤a decir que:",
            explanation: "Al ser mayor a 0.5, el modelo lo clasifica como la clase positiva (Spam).",
            options: [
                { text: "Es muy probable que sea ham", isCorrect: false },
                { text: "Es muy probable que sea spam", isCorrect: true },
                { text: "No se sabe si es spam o ham", isCorrect: false },
                { text: "No es ni spam, ni ham", isCorrect: false }
            ]
        },
        {
            topic: "Na칦ve Bayes",
            question: "Los tipos de datos que se pueden utilizar en Na칦ve Bayes pueden ser:",
            explanation: "Originalmente es para categ칩ricos (frecuencias), pero con transformaciones (Gaussian NB) acepta num칠ricos.",
            options: [
                { text: "Num칠ricos", isCorrect: false },
                { text: "Categ칩ricos", isCorrect: false },
                { text: "Num칠ricos discretizados y categ칩ricos", isCorrect: true },
                { text: "Enteros", isCorrect: false }
            ]
        },
        {
            topic: "Na칦ve Bayes",
            question: "Una ventaja del clasificador Na칦ve Bayes es:",
            explanation: "Es extremadamente r치pido y eficiente porque asume independencia, lo que simplifica enormemente los c치lculos.",
            options: [
                { text: "Es f치cil de integrar", isCorrect: false },
                { text: "Se ajusta correctamente a los datos", isCorrect: false },
                { text: "Es de bajo coste computacional", isCorrect: true },
                { text: "Los predictores se consideran independientes", isCorrect: false }
            ]
        },
        {
            topic: "Na칦ve Bayes",
            question: "Una desventaja del clasificador Na칦ve Bayes es:",
            explanation: "Su asunci칩n de 'ingenuidad' (que las variables no tienen relaci칩n entre ellas) casi nunca se cumple en la vida real.",
            options: [
                { text: "Es f치cil de integrar", isCorrect: false },
                { text: "Se ajusta correctamente a los datos", isCorrect: false },
                { text: "Es de bajo coste computacional", isCorrect: false },
                { text: "Los predictores se consideran independientes", isCorrect: true }
            ]
        },
        {
            topic: "츼rboles de Decisi칩n",
            question: "쮺u치l es la base de los 치rboles de decisi칩n?",
            explanation: "Usan medidas como Entrop칤a o 칈ndice Gini (Teor칤a de la informaci칩n) para decidir d칩nde cortar.",
            options: [
                { text: "Teor칤a de juegos", isCorrect: false },
                { text: "An치lisis estad칤stico y teor칤a de la informaci칩n", isCorrect: true },
                { text: "Transformaci칩n lineal", isCorrect: false },
                { text: "Teorema de Bayes ingenuo", isCorrect: false }
            ]
        },
        {
            topic: "츼rboles de Decisi칩n",
            question: "쯈u칠 representa cada nodo interno del 치rbol?",
            explanation: "Los nodos internos son preguntas o condiciones sobre una caracter칤stica (ej. 쮼dad > 18?).",
            options: [
                { text: "La probabilidad de una caracter칤stica", isCorrect: false },
                { text: "Una caracter칤stica", isCorrect: true },
                { text: "Una clase", isCorrect: false },
                { text: "La soluci칩n a cada instancia", isCorrect: false }
            ]
        },
        {
            topic: "츼rboles de Decisi칩n",
            question: "쯈u칠 representa cada nodo hoja del 치rbol?",
            explanation: "Las hojas son el final del camino y representan la decisi칩n final (Clase o Valor num칠rico).",
            options: [
                { text: "La probabilidad de una caracter칤stica", isCorrect: false },
                { text: "Una caracter칤stica", isCorrect: false },
                { text: "Una clase", isCorrect: true },
                { text: "La soluci칩n a cada instancia", isCorrect: false }
            ]
        },
        // === BLOQUE 6: OVERFITTING, BAGGING, RANDOM FOREST ===
        {
            topic: "츼rboles de Decisi칩n",
            question: "Los 치rboles de decisi칩n complejos pueden caer en *overfitting*:",
            explanation: "Si el 치rbol crece demasiado, empieza a memorizar el ruido de los datos de entrenamiento.",
            options: [
                { text: "Verdadero", isCorrect: true },
                { text: "Falso", isCorrect: false }
            ]
        },
        {
            topic: "츼rboles de Decisi칩n",
            question: "La estrategia de poda consiste primero generar un 치rbol grande y luego crear varios sub치rboles:",
            explanation: "Falso. La poda (pruning) consiste en cortar ramas que no aportan poder predictivo general, no en crear m칰ltiples 치rboles.",
            options: [
                { text: "Verdadero", isCorrect: false },
                { text: "Falso", isCorrect: true }
            ]
        },
        {
            topic: "츼rboles de Decisi칩n",
            question: "Siempre es mejor un algoritmo basado en 치rboles que un algoritmo basado en modelos lineales:",
            explanation: "Falso. Si la relaci칩n es lineal, una regresi칩n lineal funcionar치 mejor y ser치 m치s simple que un 치rbol.",
            options: [
                { text: "Verdadero", isCorrect: false },
                { text: "Falso", isCorrect: true }
            ]
        },
        {
            topic: "츼rboles de Decisi칩n",
            question: "Es cierto sobre los 치rboles grandes:",
            explanation: "Un 치rbol con cientos de ramas es muy dif칤cil de visualizar y entender por un humano (pierde interpretabilidad).",
            options: [
                { text: "Son dif칤ciles de interpretar", isCorrect: true },
                { text: "Son f치ciles de interpretar", isCorrect: false },
                { text: "Se deben podar siempre", isCorrect: false },
                { text: "Nunca deben podarse", isCorrect: false }
            ]
        },
        {
            topic: "츼rboles de Decisi칩n",
            question: "Una fortaleza de los 치rboles de decisi칩n es:",
            explanation: "Son vers치tiles: funcionan bien aunque tengas pocos datos o muchos datos.",
            options: [
                { text: "Se pueden utilizar con pocos o muchos datos", isCorrect: true },
                { text: "Es dif칤cilmente interpretable", isCorrect: false },
                { text: "Peque침os cambios no afectan el modelo", isCorrect: false },
                { text: "Fortalece conocimientos matem치ticos", isCorrect: false }
            ]
        },
        {
            topic: "츼rboles de Decisi칩n",
            question: "Los 치rboles de decisi칩n utilizan:",
            explanation: "El algoritmo selecciona autom치ticamente las variables que mejor separan los datos (Information Gain), ignorando las irrelevantes.",
            options: [
                { text: "Todas las variables", isCorrect: false },
                { text: "Solo variables num칠ricas", isCorrect: false },
                { text: "Solo variables categ칩ricas", isCorrect: false },
                { text: "Solo las variables importantes", isCorrect: true }
            ]
        },
        {
            topic: "Bagging / RF",
            question: "La selecci칩n de variables en la t칠cnica de *bagging* se realiza:",
            explanation: "Bagging usa Bootstrap: muestreo aleatorio con reemplazo manteniendo el mismo tama침o del dataset original.",
            options: [
                { text: "Dividiendo el conjunto de entrenamiento en subconjuntos aleatorios con la misma cantidad de individuos", isCorrect: true },
                { text: "Dividiendo en subconjuntos de diferentes tama침os", isCorrect: false },
                { text: "Dividiendo el conjunto de test", isCorrect: false },
                { text: "Dividiendo en subconjuntos iguales", isCorrect: false }
            ]
        },
        {
            topic: "Bagging / RF",
            question: "Con cada subconjunto de individuos en Bagging:",
            explanation: "Cada muestra bootstrap se divide internamente (o usa OOB) para entrenar un modelo y validarlo.",
            options: [
                { text: "Se usan todos para entrenar un mismo modelo", isCorrect: false },
                { text: "Se vuelve a dividir (train/test), se entrena un modelo y se eval칰a", isCorrect: true },
                { text: "Se entrena con todos los individuos", isCorrect: false },
                { text: "Uno se entrena y otro eval칰a", isCorrect: false }
            ]
        },
        {
            topic: "Bagging / RF",
            question: "춺Bagging췉 significa:",
            explanation: "Es el acr칩nimo de 'Bootstrap Aggregating' (o Averaging en regresi칩n).",
            options: [
                { text: "Bootstrap averaging", isCorrect: true },
                { text: "Bosques aleatorios", isCorrect: false },
                { text: "Bootstrap boosting", isCorrect: false },
                { text: "Boosting averaging", isCorrect: false }
            ]
        },
        {
            topic: "Random Forest",
            question: "La raz칩n por la cual se utilizan un gran n칰mero de 치rboles en RF es:",
            explanation: "Al tener muchos 치rboles con distintas caracter칤sticas, reducimos la varianza y evitamos que una sola variable domine el modelo.",
            options: [
                { text: "Para que cada caracter칤stica tenga la oportunidad de aparecer en varios modelos", isCorrect: true },
                { text: "No se conoce la raz칩n", isCorrect: false },
                { text: "Para evaluar las mismas caracter칤sticas", isCorrect: false },
                { text: "Para crear 치rboles con pocas caracter칤sticas", isCorrect: false }
            ]
        },
        {
            topic: "Random Forest",
            question: "El 춺out of bag error췉 es:",
            explanation: "OOB Error usa los datos que NO entraron en el muestreo bootstrap para validar el modelo, sin necesidad de un set de validaci칩n extra.",
            options: [
                { text: "Un m칠todo de medida de predicci칩n de error cuando se usa bagging", isCorrect: true },
                { text: "Una medida de sensibilidad", isCorrect: false },
                { text: "Una medida de especificidad", isCorrect: false },
                { text: "Una medida de precisi칩n", isCorrect: false }
            ]
        },
        {
            topic: "Random Forest",
            question: "쮺칩mo se realiza la selecci칩n de predictores en un *split* en *random forest*?",
            explanation: "Esta es la clave de RF: en cada nodo, solo considera un subconjunto aleatorio de variables (m) para decidir el corte.",
            options: [
                { text: "Selecci칩n aleatoria de m predictores (m = ra칤z, mitad o total)", isCorrect: true },
                { text: "Selecci칩n aleatoria, n칰mero difiere en cada split", isCorrect: false },
                { text: "Depende del problema", isCorrect: false },
                { text: "De forma secuencial", isCorrect: false }
            ]
        },
        {
            topic: "Random Forest",
            question: "Al entrenarse un modelo *random forest* se puede obtener:",
            explanation: "RF permite calcular la 'Feature Importance' viendo cu치nto disminuye el error al usar cada variable.",
            options: [
                { text: "El error de cada 치rbol y la importancia de las caracter칤sticas", isCorrect: true },
                { text: "La explicaci칩n de la decisi칩n de cada 치rbol", isCorrect: false },
                { text: "Solo la decisi칩n por 치rbol", isCorrect: false },
                { text: "Ninguna de las anteriores", isCorrect: false }
            ]
        },
        {
            topic: "Random Forest",
            question: "*Random forest* puede funcionar con variables:",
            explanation: "Es muy flexible y acepta todo tipo de datos: categor칤as, n칰meros continuos, discretos, etc.",
            options: [
                { text: "Categ칩ricas, Continuas y Discretas", isCorrect: true },
                { text: "Solo Categ칩ricas", isCorrect: false },
                { text: "Solo String", isCorrect: false },
                { text: "Solo Continuas", isCorrect: false }
            ]
        },
        {
            topic: "Random Forest",
            question: "Es FALSO cuando hablamos de *random forest*:",
            explanation: "Aunque es robusto, NO es f치cilmente interpretable (caja negra) y necesita bastantes datos para brillar.",
            options: [
                { text: "Es f치cilmente interpretable y trabaja solo con pocos datos", isCorrect: true },
                { text: "Gestiona muy bien los datos faltantes", isCorrect: false },
                { text: "Funciona bien en la mayor칤a de problemas", isCorrect: false },
                { text: "Es robusto ante ruido", isCorrect: false }
            ]
        },
        // === BLOQUE 7: ENSAMBLE, BOOSTING, SVM ===
        {
            topic: "Ensamble / Bagging",
            question: "Las t칠cnicas de ensamble de modelos hacen referencia a:",
            explanation: "La idea central es que 'muchos modelos d칠biles juntos hacen uno fuerte'.",
            options: [
                { text: "Construir varios modelos y combinar o agregar sus resultados", isCorrect: true },
                { text: "Crear varios modelos y elegir el mejor individual", isCorrect: false },
                { text: "Crear un solo modelo y ejecutarlo varias veces", isCorrect: false },
                { text: "Elegir el modelo con m칠tricas m치s altas", isCorrect: false }
            ]
        },
        {
            topic: "Ensamble / Bagging",
            question: "El t칠rmino varianza de un modelo habla de:",
            explanation: "Varianza alta significa que si cambias un poco los datos de entrenamiento, el modelo cambia radicalmente (overfitting).",
            options: [
                { text: "Cu치nto cambia un modelo dependiendo de los datos de entrenamiento utilizados", isCorrect: true },
                { text: "Un modelo que cambia constantemente en ejecuci칩n", isCorrect: false },
                { text: "Resultados diferentes tras entrenar varias veces igual", isCorrect: false },
                { text: "Modelos est치ticos que no cambian", isCorrect: false }
            ]
        },
        {
            topic: "Ensamble / Bagging",
            question: "춺Bootstrapping췉 significa:",
            explanation: "Es la t칠cnica estad칤stica de remuestreo con reemplazo para estimar propiedades de una poblaci칩n.",
            options: [
                { text: "M칠todo estad칤stico para estimar la distribuci칩n por medio del muestreo con reemplazamiento", isCorrect: true },
                { text: "Combinaci칩n de modelos con datos aleatorios", isCorrect: false },
                { text: "Ver cu치nto de significativo es un resultado", isCorrect: false },
                { text: "Ensamble sin reemplazo", isCorrect: false }
            ]
        },
        {
            topic: "Ensamble / Bagging",
            question: "El m칠todo de *bagging* permite:",
            explanation: "Al promediar muchos modelos, se suaviza el ruido y se reduce la varianza (el error por sensibilidad a los datos).",
            options: [
                { text: "Reducir la varianza de un m칠todo de machine learning", isCorrect: true },
                { text: "Calcular la varianza de varios m칠todos", isCorrect: false },
                { text: "Aumentar el sesgo significativamente", isCorrect: false },
                { text: "Crear modelos secuenciales", isCorrect: false }
            ]
        },
        {
            topic: "Ensamble / Bagging",
            question: "Es falso si hablamos de *bagging classification trees*:",
            explanation: "Para que sea Bagging puro, todos los modelos base deben ser del mismo tipo (ej. todos 치rboles).",
            options: [
                { text: "Cada modelo del conjunto puede ser un algoritmo diferente (ej. SVM + 츼rbol)", isCorrect: true },
                { text: "Es un modelo que ensambla varios 치rboles de decisi칩n", isCorrect: false },
                { text: "Estamos hablando del algoritmo base de Random Forest", isCorrect: false },
                { text: "Se entrenan B conjuntos de entrenamiento distintos", isCorrect: false }
            ]
        },
        {
            topic: "Ensamble / Bagging",
            question: "C칩mo se obtiene la predicci칩n de las instancias de test utilizando *bagging*:",
            explanation: "En clasificaci칩n es 'Voto Mayoritario' (moda); en regresi칩n es 'Promedio' (media).",
            options: [
                { text: "Voto mayoritario o promedio de la predicci칩n de todos los modelos", isCorrect: true },
                { text: "Promedio de los primeros K modelos", isCorrect: false },
                { text: "Mediana de todos los valores", isCorrect: false },
                { text: "Validaci칩n cruzada", isCorrect: false }
            ]
        },
        {
            topic: "Boosting",
            question: "Los m칠todos *boosting* construyen los modelos de forma secuencial:",
            explanation: "Verdadero. Cada modelo intenta corregir los errores del anterior (a diferencia de Bagging que es paralelo).",
            options: [
                { text: "Verdadero", isCorrect: true },
                { text: "Falso", isCorrect: false }
            ]
        },
        {
            topic: "Boosting",
            question: "Los m칠todos *boosting* ayudan a reducir el sesgo:",
            explanation: "Verdadero. Al enfocarse en los errores dif칤ciles, convierte modelos d칠biles (alto sesgo) en uno fuerte.",
            options: [
                { text: "Verdadero", isCorrect: true },
                { text: "Falso", isCorrect: false }
            ]
        },
        {
            topic: "Boosting",
            question: "En el m칠todo *boosting* se crean m칰ltiples copias del *dataset* original usando *bootstrap*:",
            explanation: "Falso. Boosting usa el mismo dataset pero asigna PESOS diferentes a las instancias seg칰n si fueron mal clasificadas.",
            options: [
                { text: "Verdadero", isCorrect: false },
                { text: "Falso", isCorrect: true }
            ]
        },
        {
            topic: "SVM (Vectores de Soporte)",
            question: "En las m치quinas de vectores de soporte (SVM) es cierto que:",
            explanation: "El 'Kernel Trick' proyecta los datos a dimensiones superiores para hacerlos linealmente separables.",
            options: [
                { text: "Se cree un espacio de caracter칤sticas superior en dimensiones al espacio de entrada", isCorrect: true },
                { text: "Se cree un espacio de caracter칤sticas", isCorrect: false },
                { text: "No se enriquece el feature space antes de separar las clases", isCorrect: false },
                { text: "Que el espacio de caracter칤sticas sea superior en dimensiones al espacio de entrada", isCorrect: false }
            ]
        },
        {
            topic: "SVM (Vectores de Soporte)",
            question: "El hiperplano es:",
            explanation: "En 2D es una l칤nea. En 3D es un plano. En n-dimensiones se llama hiperplano.",
            options: [
                { text: "Una recta en dos dimensiones y un plano en tres dimensiones", isCorrect: true },
                { text: "Siempre una recta sin importar la dimensi칩n", isCorrect: false },
                { text: "Siempre un plano en dos dimensiones", isCorrect: false },
                { text: "Un cubo en tres dimensiones", isCorrect: false }
            ]
        },
        {
            topic: "SVM (Vectores de Soporte)",
            question: "Es FALSO cuando hablamos de SVM:",
            explanation: "Fueron inventadas por Vapnik, no por Bayes. Bayes tiene su propio clasificador (Na칦ve Bayes).",
            options: [
                { text: "Fueron inventadas por Bayes", isCorrect: true },
                { text: "El t칠rmino viene del ingl칠s Support Vector Machines", isCorrect: false },
                { text: "Fueron inventadas por Vladimir Vapnik", isCorrect: false },
                { text: "Son eficaces en espacios de alta dimensi칩n", isCorrect: false }
            ]
        },
        // === BLOQUE 8: NUEVAS (SVM, REDES NEURONALES) ===
        {
            topic: "SVM",
            question: "쮺칩mo elegir el mejor hiperplano que separe dos clases?",
            explanation: "SVM busca maximizar el margen, es decir, la distancia (espacio) entre el hiperplano y los puntos m치s cercanos de ambas clases.",
            options: [
                { text: "Hay que buscar aquel que proporcione el mayor espacio entre dos clases", isCorrect: true },
                { text: "Hay que buscar aquel que proporcione el menor espacio entre dos clases", isCorrect: false },
                { text: "Hay que buscar aquel que proporcione el menor espacio entre los datos de test", isCorrect: false },
                { text: "Hay que escoger uno al azar", isCorrect: false }
            ]
        },
        {
            topic: "SVM",
            question: "Es cierto con respecto al par치metro C en SVM:",
            explanation: "Un C grande implica 'Hard Margin' (poca tolerancia al error, riesgo de overfitting). C peque침o es 'Soft Margin'.",
            options: [
                { text: "Cuanto m치s grande sea el C, menos errores se permiten", isCorrect: true },
                { text: "Un C grande permite muchos errores", isCorrect: false },
                { text: "Un C peque침o penaliza muy fuerte los errores", isCorrect: false },
                { text: "Un C peque침o no permite que las observaciones puedan estar del lado incorrecto", isCorrect: false }
            ]
        },
        {
            topic: "SVM",
            question: "Cuando hablamos de expansi칩n de caracter칤sticas es cierto que:",
            explanation: "Buscamos proyectar a una dimensi칩n mayor (D) que la original (p) para encontrar linealidad (D > p).",
            options: [
                { text: "Se pasa de un espacio p a un espacio D donde D > p", isCorrect: true },
                { text: "Se pasa de un espacio p a un espacio D donde p > D", isCorrect: false },
                { text: "Se pasa de un espacio p a un espacio D donde p = D", isCorrect: false },
                { text: "D y p siempre son iguales", isCorrect: false }
            ]
        },
        {
            topic: "SVM (Kernels)",
            question: "Un kernel en SVM es:",
            explanation: "El Kernel calcula el producto escalar en un espacio dimensional superior sin tener que transformar expl칤citamente los vectores.",
            options: [
                { text: "Es una funci칩n que recibe dos vectores como par치metros y transforma a un espacio de caracter칤sticas de mayor dimensionalidad", isCorrect: true },
                { text: "Una funci칩n que recibe un vector y transforma a un espacio de caracter칤sticas mayor", isCorrect: false },
                { text: "Un truco que utiliza el algoritmo para predecir sin entrenar", isCorrect: false },
                { text: "Una funci칩n que ayuda a elegir instancias de entrenamiento", isCorrect: false }
            ]
        },
        {
            topic: "SVM (Kernels)",
            question: "Es un tipo de kernel muy com칰n:",
            explanation: "El RBF (Radial Basis Function) es el est치ndar de facto cuando no se sabe qu칠 kernel usar.",
            options: [
                { text: "Kernel de base radial", isCorrect: true },
                { text: "Kernel ingenuo", isCorrect: false },
                { text: "Kernel basado en redes de neuronas", isCorrect: false },
                { text: "Kernel circular", isCorrect: false }
            ]
        },
        {
            topic: "SVM",
            question: "Se considera una debilidad del algoritmo SVM:",
            explanation: "Debido a su complejidad cuadr치tica/c칰bica, SVM sufre mucho en rendimiento cuando el dataset es masivo.",
            options: [
                { text: "Puede ser lento de entrenar si se tienen muchos datos y muchas columnas", isCorrect: true },
                { text: "Es muy r치pido de entrenarse sin importar la cantidad de datos", isCorrect: false },
                { text: "Funciona muy bien con datos ruidosos", isCorrect: false },
                { text: "Se puede utilizar en problemas de clasificaci칩n y regresi칩n", isCorrect: false }
            ]
        },
        {
            topic: "Redes Neuronales (Perceptr칩n)",
            question: "Una funci칩n de activaci칩n es:",
            explanation: "Es la funci칩n matem치tica que decide si la neurona 'dispara' o no, introduciendo no linealidad al modelo.",
            options: [
                { text: "Una funci칩n que define la salida de una neurona dada una entrada o un conjunto de entradas", isCorrect: true },
                { text: "Una funci칩n que utiliza regresi칩n exponencial y lineal", isCorrect: false },
                { text: "Una funci칩n que utiliza una regresi칩n log칤stica solamente", isCorrect: false },
                { text: "Una funci칩n que utiliza una regresi칩n exponencial", isCorrect: false }
            ]
        },
        {
            topic: "Redes Neuronales (Perceptr칩n)",
            question: "Un perceptr칩n est치 conformado por:",
            explanation: "Es la unidad b치sica: Entradas * Pesos + Bias -> Funci칩n de Activaci칩n -> Salida.",
            options: [
                { text: "Nodos que reciben los datos de entrada, pesos sin치pticos y una funci칩n de activaci칩n", isCorrect: true },
                { text: "Un conjunto de neuronas artificiales", isCorrect: false },
                { text: "Dendritas, ax칩n y cuerpo celular", isCorrect: false },
                { text: "Dendritas y ax칩n", isCorrect: false }
            ]
        },
        {
            topic: "Redes Neuronales (Perceptr칩n)",
            question: "D칠cada en la que se crea el perceptr칩n:",
            explanation: "Frank Rosenblatt invent칩 el Perceptr칩n en 1957 (Laboratorio Aeron치utico de Cornell).",
            options: [
                { text: "1950", isCorrect: true },
                { text: "1940", isCorrect: false },
                { text: "1930", isCorrect: false },
                { text: "1960", isCorrect: false }
            ]
        },
        {
            topic: "Redes Neuronales",
            question: "Las funciones lineales, tangente hiperb칩lica y gaussiana son funciones de activaci칩n:",
            explanation: "Verdadero. Junto con Sigmoide y ReLU, son las m치s comunes para modelar comportamientos.",
            options: [
                { text: "Verdadero", isCorrect: true },
                { text: "Falso", isCorrect: false }
            ]
        },
        {
            topic: "Redes Neuronales",
            question: "El n칰mero de capas de una red neuronal depende del n칰mero de caracter칤sticas que tenga el conjunto de datos:",
            explanation: "Falso. El n칰mero de capas (profundidad) es un hiperpar치metro de dise침o, no depende directo de las features de entrada.",
            options: [
                { text: "Verdadero", isCorrect: false },
                { text: "Falso", isCorrect: true }
            ]
        },
        {
            topic: "Redes Neuronales",
            question: "El n칰mero de neuronas de entrada depende del n칰mero de caracter칤sticas que tenga el conjunto de datos:",
            explanation: "Verdadero. La capa de entrada (input layer) debe tener tantas neuronas como columnas/features tenga tu dataset.",
            options: [
                { text: "Verdadero", isCorrect: true },
                { text: "Falso", isCorrect: false }
            ]
        },
        {
            topic: "Redes Neuronales (Backprop)",
            question: "Las fases del algoritmo de *backpropagation* son:",
            explanation: "Primero se calcula la salida (Forward) y luego se propagan los errores hacia atr치s para ajustar pesos (Backward).",
            options: [
                { text: "Fase forward y Fase backward", isCorrect: true },
                { text: "Solo Fase de reentrenamiento", isCorrect: false },
                { text: "Solo Fase de retropropagaci칩n", isCorrect: false },
                { text: "Fase de entrenamiento y Fase de validaci칩n", isCorrect: false }
            ]
        },
        {
            topic: "Redes Neuronales (Backprop)",
            question: "Para modificar los pesos de una red se utiliza:",
            explanation: "Se usa la derivada (gradiente) para saber en qu칠 direcci칩n ajustar los pesos para reducir el error global.",
            options: [
                { text: "La derivada de la funci칩n de activaci칩n de cada neurona para identificar el gradiente de la direcci칩n de los pesos futuros", isCorrect: true },
                { text: "Los pesos no se modifican", isCorrect: false },
                { text: "La direcci칩n de la mayor reducci칩n del error 칰nicamente", isCorrect: false },
                { text: "Valores aleatorios", isCorrect: false }
            ]
        },
        {
            topic: "Redes Neuronales (Fortalezas)",
            question: "Se consideran fortalezas de las redes neuronales:",
            explanation: "Son 'aproximadores universales': aprenden relaciones complejas no lineales sin que el humano tenga que definir reglas expl칤citas.",
            options: [
                { text: "Se adaptan f치cilmente a problemas de clasificaci칩n, regresi칩n, incluso a aprendizaje no supervisado", isCorrect: true },
                { text: "Gestionan muy bien los datos faltantes", isCorrect: false },
                { text: "Son un modelo de caja negra", isCorrect: false },
                { text: "Hacen pocas suposiciones sobre las relaciones de los datos", isCorrect: true } // Nota: Unifiqu칠 las respuestas correctas l칩gicas
            ]
        }
    ];

    // Variables de Estado
    let currentQuestions = [];
    let currentQuestionIndex = 0;
    let score = 0;
    let userHistory = [];
    let answered = false;

    // Referencias DOM
    const questionEl = document.getElementById('question');
    const optionsEl = document.getElementById('options');
    const feedbackEl = document.getElementById('feedback');
    const nextBtn = document.getElementById('next-btn');
    const progressFill = document.getElementById('progress');
    const questionScreen = document.getElementById('question-screen');
    const resultScreen = document.getElementById('result-screen');
    const finalGradeEl = document.getElementById('final-grade');
    const finalRawScoreEl = document.getElementById('final-raw-score');
    const controlsEl = document.getElementById('controls');
    const reviewListEl = document.getElementById('review-list');
    const recBox = document.getElementById('rec-box');
    const recText = document.getElementById('rec-text');

    function shuffleArray(array) {
        for (let i = array.length - 1; i > 0; i--) {
            const j = Math.floor(Math.random() * (i + 1));
            [array[i], array[j]] = [array[j], array[i]];
        }
        return array;
    }

    function initQuiz() {
        currentQuestionIndex = 0;
        score = 0;
        userHistory = [];
        
        let clonedData = JSON.parse(JSON.stringify(rawData));
        currentQuestions = shuffleArray(clonedData);
        currentQuestions.forEach(q => q.options = shuffleArray(q.options));

        questionScreen.style.display = 'block';
        controlsEl.style.display = 'flex';
        resultScreen.style.display = 'none';
        
        loadQuestion();
    }

    function loadQuestion() {
        answered = false;
        feedbackEl.style.display = 'none';
        nextBtn.disabled = true;
        
        const qData = currentQuestions[currentQuestionIndex];
        questionEl.innerText = `${currentQuestionIndex + 1}. ${qData.question}`;
        
        optionsEl.innerHTML = '';
        
        qData.options.forEach((opt) => {
            const btn = document.createElement('button');
            btn.innerText = opt.text;
            btn.classList.add('option-btn');
            btn.onclick = () => checkAnswer(opt, btn);
            optionsEl.appendChild(btn);
        });

        updateProgress();
    }

    function checkAnswer(selectedOption, btnElement) {
        if (answered) return;
        answered = true;

        const isCorrect = selectedOption.isCorrect;
        const qData = currentQuestions[currentQuestionIndex];
        
        userHistory.push({
            question: qData.question,
            topic: qData.topic,
            userChoice: selectedOption.text,
            correctChoice: qData.options.find(o => o.isCorrect).text,
            wasCorrect: isCorrect
        });

        const buttons = optionsEl.querySelectorAll('.option-btn');
        
        // Contenido del feedback (con explicaci칩n)
        let feedbackHTML = '';
        if (isCorrect) {
            score++;
            btnElement.classList.add('correct');
            feedbackHTML = `<span style="color: var(--success-color); font-weight:bold;">춰Correcto!</span>`;
        } else {
            btnElement.classList.add('incorrect');
            buttons.forEach(b => {
                if(b.innerText === userHistory[userHistory.length-1].correctChoice) {
                    b.classList.add('correct');
                }
            });
            feedbackHTML = `<span style="color: var(--error-color); font-weight:bold;">Incorrecto.</span>`;
        }

        // Agregar la caja de explicaci칩n
        feedbackHTML += `<div class="explanation-box"><b>Explicaci칩n:</b> ${qData.explanation}</div>`;
        
        feedbackEl.innerHTML = feedbackHTML;
        feedbackEl.style.display = 'block';
        
        nextBtn.disabled = false;
        buttons.forEach(btn => btn.disabled = true);
    }

    function nextQuestion() {
        currentQuestionIndex++;
        if (currentQuestionIndex < currentQuestions.length) {
            loadQuestion();
        } else {
            showResults();
        }
    }

    function updateProgress() {
        const percentage = ((currentQuestionIndex) / currentQuestions.length) * 100;
        progressFill.style.width = `${percentage}%`;
    }

    function showResults() {
        questionScreen.style.display = 'none';
        controlsEl.style.display = 'none';
        resultScreen.style.display = 'block';
        progressFill.style.width = '100%';
        
        const total = currentQuestions.length;
        const grade = (score / total) * 10;
        
        finalGradeEl.innerText = grade.toFixed(1);
        
        const circle = document.querySelector('.grade-circle');
        if(grade >= 9) circle.style.backgroundColor = '#22c55e';
        else if(grade >= 6) circle.style.backgroundColor = '#eab308';
        else circle.style.backgroundColor = '#ef4444';

        finalRawScoreEl.innerText = `${score} / ${total}`;

        generateRecommendation(grade);
        generateReview();
    }

    function generateRecommendation(grade) {
        recBox.style.display = 'block';
        
        if (grade === 10) {
            recText.innerText = "춰Excelente! Has dominado todos los conceptos.";
            return;
        }

        const wrongTopics = {};
        userHistory.forEach(item => {
            if (!item.wasCorrect) {
                if (!wrongTopics[item.topic]) wrongTopics[item.topic] = 0;
                wrongTopics[item.topic]++;
            }
        });

        const topicsSorted = Object.keys(wrongTopics).sort((a,b) => wrongTopics[b] - wrongTopics[a]);

        if (topicsSorted.length > 0) {
            let msg = "Para mejorar tu nota, repasa: ";
            const topTopics = topicsSorted.slice(0, 3).map(t => `<b>${t}</b>`);
            msg += topTopics.join(", ") + ".";
            recText.innerHTML = msg;
        } else {
            recText.innerText = "Revisa los detalles abajo para ver tus errores puntuales.";
        }
    }

    function generateReview() {
        reviewListEl.innerHTML = "<h3>Resumen detallado:</h3>";
        
        userHistory.forEach((item, index) => {
            const div = document.createElement('div');
            div.classList.add('review-item');
            div.classList.add(item.wasCorrect ? 'correct-item' : 'wrong-item');
            
            div.innerHTML = `
                <div class="review-q">
                    ${index + 1}. ${item.question} 
                    <span class="tag-pill">${item.topic}</span>
                </div>
                <div>Tu respuesta: <b>${item.userChoice}</b></div>
                ${!item.wasCorrect ? `<div style="color:var(--success-color); margin-top:4px;">Correcta: <b>${item.correctChoice}</b></div>` : ''}
            `;
            
            reviewListEl.appendChild(div);
        });
    }

    initQuiz();

</script>
</body>
</html>